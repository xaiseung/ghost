{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/kornia/augmentation/augmentation.py:1830: DeprecationWarning: GaussianBlur is no longer maintained and will be removed from the future versions. Please use RandomGaussianBlur instead.\n",
      "  warnings.warn(\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/mxnet/numpy/fallback.py:143: DeprecationWarning: In accordance with NEP 32, the function mirr was removed from NumPy version 1.20.  A replacement for this function is available in the numpy_financial library: https://pypi.org/project/numpy-financial\n",
      "  mirr = onp.mirr\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/mxnet/numpy/fallback.py:160: DeprecationWarning: In accordance with NEP 32, the function npv was removed from NumPy version 1.20.  A replacement for this function is available in the numpy_financial library: https://pypi.org/project/numpy-financial\n",
      "  npv = onp.npv\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/mxnet/numpy/fallback.py:164: DeprecationWarning: In accordance with NEP 32, the function pmt was removed from NumPy version 1.20.  A replacement for this function is available in the numpy_financial library: https://pypi.org/project/numpy-financial\n",
      "  pmt = onp.pmt\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/mxnet/numpy/fallback.py:173: DeprecationWarning: In accordance with NEP 32, the function ppmt was removed from NumPy version 1.20.  A replacement for this function is available in the numpy_financial library: https://pypi.org/project/numpy-financial\n",
      "  ppmt = onp.ppmt\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/mxnet/numpy/fallback.py:176: DeprecationWarning: In accordance with NEP 32, the function pv was removed from NumPy version 1.20.  A replacement for this function is available in the numpy_financial library: https://pypi.org/project/numpy-financial\n",
      "  pv = onp.pv\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/mxnet/numpy/fallback.py:177: DeprecationWarning: In accordance with NEP 32, the function rate was removed from NumPy version 1.20.  A replacement for this function is available in the numpy_financial library: https://pypi.org/project/numpy-financial\n",
      "  rate = onp.rate\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/mxnet/numpy_dispatch_protocol.py:48: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  cur_np_ver = LooseVersion(_np.__version__)\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/mxnet/numpy_dispatch_protocol.py:49: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  np_1_17_ver = LooseVersion('1.17')\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/mxnet/numpy_dispatch_protocol.py:68: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  cur_np_ver = LooseVersion(_np.__version__)\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/mxnet/numpy_dispatch_protocol.py:69: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  np_1_15_ver = LooseVersion('1.15')\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "def nop(it, *a, **k):\n",
    "    return it\n",
    "\n",
    "real_tqdm = tqdm.tqdm\n",
    "tqdm.tqdm = nop\n",
    "\n",
    "import scipy\n",
    "scipy.sparse.csr.csr_matrix = scipy.sparse.csr_matrix\n",
    "\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "from typing import Union, List\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "np.bool = np.bool_\n",
    "import cv2\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils.inference.image_processing import crop_face, get_final_image, show_images, normalize_and_torch, normalize_and_torch_batch\n",
    "from utils.inference.video_processing import read_video, get_target, get_final_video, add_audio_from_another_video, face_enhancement, crop_frames_and_get_transforms, resize_frames\n",
    "from utils.inference.core import model_inference, transform_target_to_torch\n",
    "from utils.inference.faceshifter_run import faceshifter_batch, faceshifter_batch_zattrs\n",
    "from network.AEI_Net import AEI_Net\n",
    "from coordinate_reg.image_infer import Handler\n",
    "from insightface_func.face_detect_crop_multi import Face_detect_crop\n",
    "from arcface_model.iresnet import iresnet100\n",
    "from models.pix2pix_model import Pix2PixModel\n",
    "from models.config_sr import TestOptions\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinglePCA:\n",
    "    def __init__(self, layer_id, root_path=\"./pca_pkl\", use_norm=False):\n",
    "        self.layer_id = layer_id\n",
    "        self.use_norm = use_norm # -1~1\n",
    "        with open(f\"{root_path}/Altered_zattr{self.layer_id}PCA.pkl\", \"rb\") as file:\n",
    "            self.pca = pickle.load(file)\n",
    "        with open(f\"{root_path}/Altered_zattr{self.layer_id}PCAMinMax.pkl\", \"rb\") as file:\n",
    "            minmax = pickle.load(file)\n",
    "        self.pca_min = minmax[\"min\"]\n",
    "        self.pca_max = minmax[\"max\"]\n",
    "    \n",
    "    def transform(self, z_embed:np.ndarray) -> np.ndarray:\n",
    "        return self.pca.transform(z_embed)\n",
    "    \n",
    "    def inverse_transform(self, p_emb:np.ndarray) -> np.ndarray:\n",
    "        return self.pca.inverse_transform(p_emb)\n",
    "\n",
    "    def calcul_z_embed_diff(self, target:np.ndarray, original:np.ndarray)->np.ndarray:\n",
    "        target = self.inverse_transform(target)\n",
    "        original = self.inverse_transform(original)\n",
    "        return target-original\n",
    "    \n",
    "    def inject_pca_param(self, orig_z_embeds: List[np.ndarray], pca_param:dict, add=False)->List[np.ndarray]:\n",
    "        p_emb = self.transform(orig_z_embeds[self.layer_id])\n",
    "        orig_p_emb = p_emb.copy()\n",
    "        if self.use_norm:\n",
    "            for k in pca_param:\n",
    "                if add:\n",
    "                    p_emb[:, k] += pca_param[k] * (self.pca_max[k]-self.pca_min[k])/2\n",
    "                else:\n",
    "                    p_emb[:, k] = self.pca_min[k] + (pca_param[k]+1)/2*(self.pca_max[k]-self.pca_min[k])\n",
    "        else:\n",
    "            for k in pca_param:\n",
    "                p_emb[:, k] = pca_param[k]+p_emb[:, k]*int(add)\n",
    "        res_z_embeds = copy.deepcopy(orig_z_embeds)\n",
    "        res_z_embeds[self.layer_id] += self.calcul_z_embed_diff(p_emb, orig_p_emb)\n",
    "        return res_z_embeds\n",
    "\n",
    "class DoublePCA:\n",
    "    def __init__(self, layer_num=8, root_path=\"./pca_pkl\", use_norm=False):\n",
    "        self.layer_num = layer_num\n",
    "        self.use_norm = use_norm # -1~1\n",
    "\n",
    "        self.pca1_list = []\n",
    "        for z_i in range(self.layer_num):\n",
    "            with open(f\"{root_path}/Altered_zattr{z_i}PCA.pkl\", \"rb\") as file:\n",
    "                self.pca1_list.append(pickle.load(file))\n",
    "        with open(f\"{root_path}/Altered_zattr_doublePCA.pkl\", \"rb\") as file:\n",
    "            self.pca2 = pickle.load(file)\n",
    "        with open(f\"{root_path}/Altered_zattr_doublePCAMinMax.pkl\", \"rb\") as file:\n",
    "            minmax = pickle.load(file)\n",
    "        self.pca2_min = minmax[\"min\"]\n",
    "        self.pca2_max = minmax[\"max\"]\n",
    "    def transform(self, z_embeds) -> np.ndarray:\n",
    "        p1emb_array = [self.pca1_list[z_i].transform(z_embeds[z_i]) for z_i in range(self.layer_num)]\n",
    "        p1emb_array = np.concatenate(p1emb_array, axis=1)\n",
    "        return self.pca2.transform(p1emb_array)\n",
    "\n",
    "    def inverse_transform(self, p2emb_array)->List[np.ndarray]:\n",
    "        p1emb_array = self.pca2.inverse_transform(p2emb_array).reshape([-1, self.layer_num, 128])\n",
    "        z_embeds = [self.pca1_list[z_i].inverse_transform(p1emb_array[:,z_i]) for z_i in range(self.layer_num)]\n",
    "        return z_embeds\n",
    "\n",
    "    def calcul_z_embed_diff(self, target:np.ndarray, original:np.ndarray)->List[np.ndarray]:\n",
    "        assert target.shape[0] == original.shape[0]\n",
    "        target = self.inverse_transform(target)\n",
    "        original = self.inverse_transform(original)\n",
    "        return [target[i]-original[i] for i in range(self.layer_num)]\n",
    "\n",
    "    def inject_pca_param(self, orig_z_embeds: List[np.ndarray], pca_param:dict, add=False)->List[np.ndarray]:\n",
    "        p2emb = self.transform(orig_z_embeds)\n",
    "        orig_p2embed = p2emb.copy()\n",
    "        if self.use_norm:\n",
    "            for k in pca_param:\n",
    "                if add:\n",
    "                    p2emb[:, k] += pca_param[k] * (self.pca_max[k]-self.pca_min[k])/2\n",
    "                else:\n",
    "                    p2emb[:, k] = self.pca_min[k] + (pca_param[k]+1)/2*(self.pca_max[k]-self.pca_min[k])\n",
    "        else:\n",
    "            for k in pca_param:\n",
    "                p2emb[:, k] = pca_param[k]+p2emb[:, k]*int(add)\n",
    "        diff = self.calcul_z_embed_diff(p2emb, orig_p2embed)\n",
    "        return [orig_z_embeds[i]+diff[i] for i in range(len(orig_z_embeds))]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class FaceSwap_PCAInjection():\n",
    "\n",
    "    def __init__(self, pca_mode=\"double\",pca_use_norm=False):\n",
    "        self.crop_size = 224 \n",
    "\n",
    "        self.app = Face_detect_crop(name='antelope', root='./insightface_func/models')\n",
    "        self.app.prepare(ctx_id= 0, det_thresh=0.6, det_size=(640,640))\n",
    "\n",
    "        # main model for generation\n",
    "        self.G = AEI_Net(backbone='unet', num_blocks=2, c_id=512)\n",
    "        self.G.eval()\n",
    "        self.G.load_state_dict(torch.load('weights/G_unet_2blocks.pth', map_location=torch.device('cpu')))\n",
    "        self.G = self.G.cuda()\n",
    "        self.G = self.G.half()\n",
    "\n",
    "        # arcface model to get face embedding\n",
    "        self.netArc = iresnet100(fp16=False)\n",
    "        self.netArc.load_state_dict(torch.load('arcface_model/backbone.pth'))\n",
    "        self.netArc = self.netArc.cuda()\n",
    "        self.netArc.eval()\n",
    "\n",
    "        # model to get face landmarks\n",
    "        self.handler = Handler('./coordinate_reg/model/2d106det', 0, ctx_id=0, det_size=640)\n",
    "\n",
    "        # model to make superres of face, set use_sr=True if you want to use super resolution or use_sr=False if you don't\n",
    "        opt = TestOptions()\n",
    "        #opt.which_epoch ='10_7'\n",
    "        self.model = Pix2PixModel(opt)\n",
    "        self.model.netG.train()\n",
    "        if pca_mode == \"double\":\n",
    "            self.pca = DoublePCA(use_norm=pca_use_norm)\n",
    "        else:\n",
    "            try:\n",
    "                pca_mode = int(pca_mode)\n",
    "                assert pca_mode >= 0 and pca_mode <= 7\n",
    "                self.pca = SinglePCA(pca_mode, use_norm=pca_use_norm)\n",
    "            except:\n",
    "                raise ValueError(\"pca_mode should be 'double' or integer in [0~7]\")\n",
    "\n",
    "        \n",
    "    \n",
    "    def swap_face(self, source: Union[np.ndarray, str],\n",
    "                    target: Union[np.ndarray, str],\n",
    "                    is_tgt_video=False,\n",
    "                    BS = 60,\n",
    "                    pca_param: dict = None,\n",
    "                    pca_add: bool = False):\n",
    "        \"\"\" # TODO\n",
    "\n",
    "        source와 target은 cv2.imread의 출력, 즉 bgr ndarray 입력으로 간주한다.\n",
    "        단, target이 영상인 경우에는 [t, H, W, C]꼴의 ndarray 리스트 입력으로 생각한다\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        if isinstance(source, str):\n",
    "            source = cv2.imread(source)\n",
    "        source = [crop_face(source, self.app, self.crop_size)[0][:,:,::-1]]\n",
    "\n",
    "        if isinstance(target, str):\n",
    "            if is_tgt_video:\n",
    "                full_frames, fps = read_video(tgt)\n",
    "            else:\n",
    "                target_full = cv2.imread(target)\n",
    "                full_frames = [target_full]\n",
    "        else:\n",
    "            full_frames = target if is_tgt_video else [target]\n",
    "\n",
    "        cropped_target = get_target(full_frames, self.app, self.crop_size)\n",
    "        target_norm = normalize_and_torch_batch(np.array(cropped_target))\n",
    "        target_embeds = self.netArc(F.interpolate(target_norm, scale_factor=0.5, mode='bilinear', align_corners=True))\n",
    "        crop_frames_list, tfm_array_list = crop_frames_and_get_transforms(full_frames,\n",
    "                                                                    target_embeds,\n",
    "                                                                    self.app,\n",
    "                                                                    self.netArc,\n",
    "                                                                    self.crop_size,\n",
    "                                                                    set_target=False,\n",
    "                                                                    similarity_th=0.15\n",
    "                                                                    )\n",
    "        crop_frames_list = crop_frames_list\n",
    "        tfm_array_list = tfm_array_list\n",
    "\n",
    "        source_embeds = []\n",
    "        for source_curr in source:\n",
    "            source_curr = normalize_and_torch(source_curr)\n",
    "            source_embeds.append(self.netArc(F.interpolate(source_curr, scale_factor=0.5, mode='bilinear', align_corners=True)))\n",
    "\n",
    "        final_frames_list = []\n",
    "        for idx, (crop_frames, tfm_array, source_embed) in enumerate(zip(crop_frames_list, tfm_array_list, source_embeds)):\n",
    "            # Resize croped frames and get vector which shows on which frames there were faces\n",
    "            resized_frs, present = resize_frames(crop_frames)\n",
    "            resized_frs = np.array(resized_frs)\n",
    "\n",
    "            # transform embeds of Xs and target frames to use by model\n",
    "            target_batch_rs = transform_target_to_torch(resized_frs, half=True)\n",
    "            #assert False\n",
    "            source_embed = source_embed.half()\n",
    "\n",
    "            # run model\n",
    "            size = target_batch_rs.shape[0]\n",
    "            model_output = []\n",
    "            for i in range(0, size, BS):\n",
    "                zattrs = self.G.get_attr(target_batch_rs[i:i+BS])\n",
    "                if pca_param:\n",
    "                    orig_z_shape = [zattrs[j].shape for j in range(len(zattrs))]\n",
    "                    np_zattrs = [zattrs[j].detach().cpu().numpy().reshape([orig_z_shape[j][0], -1]) for j in range(len(zattrs))]\n",
    "                    injected_z = self.pca.inject_pca_param(np_zattrs, pca_param, add=pca_add)\n",
    "                    zattrs = [torch.from_numpy(injected_z[j].reshape(*orig_z_shape[j])).half().cuda() for j in range(len(orig_z_shape))]\n",
    "                Y_st = faceshifter_batch_zattrs(source_embed, zattrs, BS, self.G)\n",
    "                model_output.append(Y_st)\n",
    "            torch.cuda.empty_cache()\n",
    "            model_output = np.concatenate(model_output)\n",
    "\n",
    "            # create list of final frames with transformed faces\n",
    "            final_frames = []\n",
    "            idx_fs = 0\n",
    "            for pres in present:\n",
    "                if pres == 1:\n",
    "                    final_frames.append(model_output[idx_fs])\n",
    "                    idx_fs += 1\n",
    "                else:\n",
    "                    final_frames.append([])\n",
    "            final_frames_list.append(final_frames)\n",
    "\n",
    "        final_frames_list = face_enhancement(final_frames_list, self.model)\n",
    "        \n",
    "        if is_tgt_video:\n",
    "            assert False, \"not implemented\"\n",
    "        else:\n",
    "            result = get_final_image(final_frames_list, crop_frames_list, full_frames[0], tfm_array_list, self.handler)\n",
    "        return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input mean and std: 127.5 127.5\n",
      "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
      "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
      "set det-size: (640, 640)\n",
      "loading ./coordinate_reg/model/2d106det 0\n",
      "input mean and std: 127.5 127.5\n",
      "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
      "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
      "set det-size: (640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05:36:22] ../src/nnvm/legacy_json_util.cc:208: Loading symbol saved by previous version v1.5.0. Attempting to upgrade...\n",
      "[05:36:22] ../src/nnvm/legacy_json_util.cc:216: Symbol successfully upgraded!\n",
      "[05:36:22] ../src/base.cc:79: cuDNN lib mismatch: linked-against version 8204 != compiled-against version 8101.  Set MXNET_CUDNN_LIB_CHECKING=0 to quiet this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network [LIPSPADEGenerator] was created. Total number of parameters: 72.2 million. To see the architecture, do print(network).\n",
      "Load checkpoint from path:  weights/10_net_G.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/ipywidgets/widgets/widget.py:503: DeprecationWarning: Passing unrecognized arguments to super(FileUpload).__init__(aceept='').\n",
      "object.__init__() takes exactly one argument (the instance to initialize)\n",
      "This is deprecated in traitlets 4.2.This error will be raised in a future release of traitlets.\n",
      "  super().__init__(**kwargs)\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/ipywidgets/widgets/widget.py:503: DeprecationWarning: Passing unrecognized arguments to super(FileUpload).__init__(aceept='').\n",
      "object.__init__() takes exactly one argument (the instance to initialize)\n",
      "This is deprecated in traitlets 4.2.This error will be raised in a future release of traitlets.\n",
      "  super().__init__(**kwargs)\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/ipywidgets/widgets/interaction.py:43: DeprecationWarning: `ipykernel.pylab.backend_inline` is deprecated, directly use `matplotlib_inline.backend_inline`\n",
      "  from ipykernel.pylab.backend_inline import flush_figures\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5e9140d984c44f1bd81ab7f34b2ac2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FileUpload(value=(), description='Source Upload'), FileUpload(value=(), description='Target Upl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95c11fd1d4a247458779298d5be2e666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "faceswap = FaceSwap_PCAInjection(pca_mode=5,pca_use_norm=True)\n",
    "\n",
    "source_upload = widgets.FileUpload(\n",
    "    description=\"Source Upload\",\n",
    "    aceept=\"\",\n",
    "    multiple=False\n",
    ")\n",
    "target_upload = widgets.FileUpload(\n",
    "    description=\"Target Upload\",\n",
    "    aceept=\"\",\n",
    "    multiple=False\n",
    ")\n",
    "smile_button = widgets.ToggleButton(\n",
    "    value=False,\n",
    "    description=\"Make you Smile ;)\",\n",
    "    disabled=False,\n",
    "    icon=\"\"\n",
    ")\n",
    "\n",
    "line1_multibox = widgets.HBox(\n",
    "    children=[source_upload,\n",
    "    target_upload,\n",
    "    smile_button\n",
    "    ]\n",
    ")\n",
    "\n",
    "def plotting(source_value, target_value, smile: bool):\n",
    "    if bool(source_value) and bool(target_value):\n",
    "        source = cv2.imdecode(np.asarray(source_value[0][\"content\"], dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "        target = cv2.imdecode(np.asarray(target_value[0][\"content\"], dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "        plt.figure(num=1, clear=True, figsize=[12+int(smile)*4, 4])\n",
    "        plt.subplot(1, 3+int(smile), 1)\n",
    "        plt.imshow(source[:, :, ::-1])\n",
    "        plt.axis(\"off\")\n",
    "        plt.subplot(1, 3+int(smile), 2)\n",
    "        plt.imshow(target[:, :, ::-1])\n",
    "        plt.axis(\"off\")\n",
    "        result = faceswap.swap_face(\n",
    "            source=source,\n",
    "            target=target)\n",
    "        plt.subplot(1, 3+int(smile), 3)\n",
    "        plt.imshow(result[:, :, ::-1])\n",
    "        plt.axis(\"off\")\n",
    "        if smile:\n",
    "            plt.subplot(1, 3+int(smile), 4)\n",
    "            result = faceswap.swap_face(\n",
    "            source=source,\n",
    "            target=target,\n",
    "            pca_param={8:1.5})\n",
    "            plt.imshow(result[:, :, ::-1])\n",
    "            plt.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "\n",
    "iplot = widgets.interactive_output(plotting,\n",
    "                                   {'source_value':source_upload,\n",
    "                                    'target_value':target_upload,\n",
    "                                    'smile':smile_button\n",
    "                                    })\n",
    "\n",
    "display(line1_multibox, iplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 영상 받을려고 만지작거리는 코드\n",
    "# 미완성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74db7f9f12004210a9570a9b2ae034ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FileUpload(value=(), description='Source Upload'), FileUpload(value=(), description='Target Upl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "source_upload = widgets.FileUpload(\n",
    "    description=\"Source Upload\",\n",
    "    aceept=\"\",\n",
    "    multiple=False\n",
    ")\n",
    "target_upload = widgets.FileUpload(\n",
    "    description=\"Target Upload\",\n",
    "    aceept=\"\",\n",
    "    multiple=False\n",
    ")\n",
    "\n",
    "line1_multibox = widgets.HBox(\n",
    "    children=[source_upload,\n",
    "    target_upload,\n",
    "    ]\n",
    ")\n",
    "display(line1_multibox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'name': 'what_is_love_kekw.mp4', 'type': 'video/mp4', 'size': 231549, 'content': <memory at 0x7fad02c98940>, 'last_modified': datetime.datetime(2024, 4, 12, 8, 16, 7, 476000, tzinfo=datetime.timezone.utc)},)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR:0@493.528] global cap.cpp:164 open VIDEOIO(CV_IMAGES): raised OpenCV exception:\n",
      "\n",
      "OpenCV(4.9.0) /io/opencv/modules/videoio/src/cap_images.cpp:300: error: (-215:Assertion failed) !_filename.empty() in function 'open'\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(source_upload.value)\n",
    "source_upload.value[0].type\n",
    "\n",
    "\n",
    "video_stream = cv2.imdecode(np.frombuffer(source_upload.value[0][\"content\"], dtype=np.uint8), cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# 메모리 버퍼로부터 동영상을 읽어들이기 위해 VideoCapture 객체 생성\n",
    "video_capture = cv2.VideoCapture(video_stream)\n",
    "\n",
    "while video_capture.isOpened():\n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # 프레임 처리 (여기서 필요한 작업을 수행)\n",
    "    cv2.imshow('Frame', frame)\n",
    "\n",
    "    # 'q' 키를 누르면 루프 종료\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# 자원 해제\n",
    "video_capture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"temp_video.mp4\", \"wb\") as f:\n",
    "    f.write(source_upload.value[0][\"content\"].tobytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'jaeseung_2_heheboi.mp4',\n",
       " 'type': 'video/mp4',\n",
       " 'size': 511907,\n",
       " 'content': <memory at 0x7face36bb880>,\n",
       " 'last_modified': datetime.datetime(2024, 4, 11, 12, 24, 44, 792000, tzinfo=datetime.timezone.utc)}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_upload.value[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%conda install panel watchfiles jupyter_bokeh -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.4.0'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.0.min.js\", \"https://cdn.holoviz.org/panel/1.4.2/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n\ttry {\n          inline_js[i].call(root, root.Bokeh);\n\t} catch(e) {\n\t  if (!reloading) {\n\t    throw e;\n\t  }\n\t}\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='cb3b90fd-350d-4649-a0df-6c914ef6519f'>\n",
       "  <div id=\"cb0b33ef-10b4-4657-8d86-6b08a82fdfb4\" data-root-id=\"cb3b90fd-350d-4649-a0df-6c914ef6519f\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"a5a77192-1532-45d4-9d13-55157487f7f9\":{\"version\":\"3.4.0\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"cb3b90fd-350d-4649-a0df-6c914ef6519f\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"08d67891-c15d-45c8-9c5f-2b8f8212d845\",\"attributes\":{\"plot_id\":\"cb3b90fd-350d-4649-a0df-6c914ef6519f\",\"comm_id\":\"01c9caeaabfc42c482b9878b5fcc2e8e\",\"client_comm_id\":\"b7c0050b00e646819ac24ecb23696f13\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":null}]}]}};\n",
       "  var render_items = [{\"docid\":\"a5a77192-1532-45d4-9d13-55157487f7f9\",\"roots\":{\"cb3b90fd-350d-4649-a0df-6c914ef6519f\":\"cb0b33ef-10b4-4657-8d86-6b08a82fdfb4\"},\"root_ids\":[\"cb3b90fd-350d-4649-a0df-6c914ef6519f\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && (id_el.children[0].className === 'bk-root')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "cb3b90fd-350d-4649-a0df-6c914ef6519f"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e21852381e8f4fb4aef627bb0e327015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(combine_events=True, render_bundle={'docs_json': {'d082c10f-0e6a-4136-a55b-3c89d78af469': {'version…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import panel as pn\n",
    "pn.extension()\n",
    "file_input = pn.widgets.FileInput()\n",
    "display(file_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(file_input.value)\n",
    "if file_input.value is not None:\n",
    "    file_input.save('test.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(511907,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.frombuffer(source_upload.value[0][\"content\"], dtype=np.uint8).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture()\n",
    "video_capture.get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 구 사용 예제 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input mean and std: 127.5 127.5\n",
      "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
      "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
      "set det-size: (640, 640)\n",
      "loading ./coordinate_reg/model/2d106det 0\n",
      "input mean and std: 127.5 127.5\n",
      "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
      "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
      "set det-size: (640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10:06:48] ../src/nnvm/legacy_json_util.cc:208: Loading symbol saved by previous version v1.5.0. Attempting to upgrade...\n",
      "[10:06:48] ../src/nnvm/legacy_json_util.cc:216: Symbol successfully upgraded!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network [LIPSPADEGenerator] was created. Total number of parameters: 72.2 million. To see the architecture, do print(network).\n",
      "Load checkpoint from path:  weights/10_net_G.pth\n"
     ]
    }
   ],
   "source": [
    "faceswap = FaceSwap_PCAInjection(pca_mode=5,pca_use_norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no injection\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'faceswap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno injection\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m target \u001b[38;5;129;01min\u001b[39;00m [\n",
      "\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexamples/images/jaeseung_3.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexamples/images/great-faker.webp\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexamples/images/tgt2.png\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[1;32m      6\u001b[0m     ]:\n",
      "\u001b[0;32m----> 8\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfaceswap\u001b[49m\u001b[38;5;241m.\u001b[39mswap_face(\n",
      "\u001b[1;32m      9\u001b[0m         source\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexamples/images/elon_musk.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[1;32m     10\u001b[0m         target\u001b[38;5;241m=\u001b[39mtarget)\n",
      "\u001b[1;32m     12\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(result[:, :, ::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[1;32m     13\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m: name 'faceswap' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"no injection\")\n",
    "for target in [\n",
    "    \"examples/images/jaeseung_3.jpg\",\n",
    "    \"examples/images/great-faker.webp\",\n",
    "    \"examples/images/tgt2.png\",\n",
    "    ]:\n",
    "\n",
    "    result = faceswap.swap_face(\n",
    "        source=\"examples/images/elon_musk.jpg\",\n",
    "        target=target)\n",
    "\n",
    "    plt.imshow(result[:, :, ::-1])\n",
    "    plt.show()\n",
    "print(\"=\"*30)\n",
    "print(\"=\"*30)\n",
    "print(\"After inject\")\n",
    "for target in [\n",
    "    \"examples/images/jaeseung_3.jpg\",\n",
    "    \"examples/images/great-faker.webp\",\n",
    "    \"examples/images/tgt2.png\",\n",
    "    ]:\n",
    "\n",
    "    result = faceswap.swap_face(\n",
    "        source=\"examples/images/elon_musk.jpg\",\n",
    "        target=target,\n",
    "        pca_param={\n",
    "            8: 1.5},\n",
    "        pca_add=True)\n",
    "\n",
    "    plt.imshow(result[:, :, ::-1])\n",
    "    plt.show()\n",
    "\n",
    "print(\"=\"*30)\n",
    "print(\"=\"*30)\n",
    "print(\"After inject\")\n",
    "for target in [\n",
    "    \"examples/images/jaeseung_3.jpg\",\n",
    "    \"examples/images/great-faker.webp\",\n",
    "    \"examples/images/tgt2.png\",\n",
    "    ]:\n",
    "\n",
    "    result = faceswap.swap_face(\n",
    "        source=\"examples/images/elon_musk.jpg\",\n",
    "        target=target,\n",
    "        pca_param={\n",
    "            8: 1.5},\n",
    "        pca_add=False)\n",
    "\n",
    "    plt.imshow(result[:, :, ::-1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msource_upload\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconetent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "source_upload.value[\"conetent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xaiseung_ghost_cuda114",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
