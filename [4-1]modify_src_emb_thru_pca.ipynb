{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "published-metro",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/kornia/augmentation/augmentation.py:1830: DeprecationWarning: GaussianBlur is no longer maintained and will be removed from the future versions. Please use RandomGaussianBlur instead.\n",
      "  warnings.warn(\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/mxnet/numpy/fallback.py:143: DeprecationWarning: In accordance with NEP 32, the function mirr was removed from NumPy version 1.20.  A replacement for this function is available in the numpy_financial library: https://pypi.org/project/numpy-financial\n",
      "  mirr = onp.mirr\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/mxnet/numpy/fallback.py:160: DeprecationWarning: In accordance with NEP 32, the function npv was removed from NumPy version 1.20.  A replacement for this function is available in the numpy_financial library: https://pypi.org/project/numpy-financial\n",
      "  npv = onp.npv\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/mxnet/numpy/fallback.py:164: DeprecationWarning: In accordance with NEP 32, the function pmt was removed from NumPy version 1.20.  A replacement for this function is available in the numpy_financial library: https://pypi.org/project/numpy-financial\n",
      "  pmt = onp.pmt\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/mxnet/numpy/fallback.py:173: DeprecationWarning: In accordance with NEP 32, the function ppmt was removed from NumPy version 1.20.  A replacement for this function is available in the numpy_financial library: https://pypi.org/project/numpy-financial\n",
      "  ppmt = onp.ppmt\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/mxnet/numpy/fallback.py:176: DeprecationWarning: In accordance with NEP 32, the function pv was removed from NumPy version 1.20.  A replacement for this function is available in the numpy_financial library: https://pypi.org/project/numpy-financial\n",
      "  pv = onp.pv\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/mxnet/numpy/fallback.py:177: DeprecationWarning: In accordance with NEP 32, the function rate was removed from NumPy version 1.20.  A replacement for this function is available in the numpy_financial library: https://pypi.org/project/numpy-financial\n",
      "  rate = onp.rate\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/mxnet/numpy_dispatch_protocol.py:48: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  cur_np_ver = LooseVersion(_np.__version__)\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/mxnet/numpy_dispatch_protocol.py:49: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  np_1_17_ver = LooseVersion('1.17')\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/mxnet/numpy_dispatch_protocol.py:68: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  cur_np_ver = LooseVersion(_np.__version__)\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/mxnet/numpy_dispatch_protocol.py:69: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  np_1_15_ver = LooseVersion('1.15')\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "def nop(it, *a, **k):\n",
    "    return it\n",
    "\n",
    "real_tqdm = tqdm.tqdm\n",
    "tqdm.tqdm = nop\n",
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "import time\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "np.bool = np.bool_\n",
    "import cv2\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils.inference.image_processing import crop_face, get_final_image, show_images, normalize_and_torch, normalize_and_torch_batch\n",
    "from utils.inference.video_processing import read_video, get_target, get_final_video, add_audio_from_another_video, face_enhancement, crop_frames_and_get_transforms, resize_frames\n",
    "from utils.inference.core import model_inference, transform_target_to_torch\n",
    "from utils.inference.faceshifter_run import faceshifter_batch\n",
    "from network.AEI_Net import AEI_Net\n",
    "from coordinate_reg.image_infer import Handler\n",
    "from insightface_func.face_detect_crop_multi import Face_detect_crop\n",
    "from arcface_model.iresnet import iresnet100\n",
    "from models.pix2pix_model import Pix2PixModel\n",
    "from models.config_sr import TestOptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-factor",
   "metadata": {},
   "source": [
    "### Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "signed-mustang",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input mean and std: 127.5 127.5\n",
      "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
      "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
      "set det-size: (640, 640)\n",
      "loading ./coordinate_reg/model/2d106det 0\n",
      "input mean and std: 127.5 127.5\n",
      "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
      "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
      "set det-size: (640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[04:09:09] ../src/nnvm/legacy_json_util.cc:208: Loading symbol saved by previous version v1.5.0. Attempting to upgrade...\n",
      "[04:09:09] ../src/nnvm/legacy_json_util.cc:216: Symbol successfully upgraded!\n",
      "[04:09:09] ../src/base.cc:79: cuDNN lib mismatch: linked-against version 8302 != compiled-against version 8101.  Set MXNET_CUDNN_LIB_CHECKING=0 to quiet this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network [LIPSPADEGenerator] was created. Total number of parameters: 72.2 million. To see the architecture, do print(network).\n",
      "Load checkpoint from path:  weights/10_net_G.pth\n"
     ]
    }
   ],
   "source": [
    "app = Face_detect_crop(name='antelope', root='./insightface_func/models')\n",
    "app.prepare(ctx_id= 0, det_thresh=0.6, det_size=(640,640))\n",
    "\n",
    "# main model for generation\n",
    "G = AEI_Net(backbone='unet', num_blocks=2, c_id=512)\n",
    "G.eval()\n",
    "G.load_state_dict(torch.load('weights/G_unet_2blocks.pth', map_location=torch.device('cpu')))\n",
    "G = G.cuda()\n",
    "G = G.half()\n",
    "\n",
    "# arcface model to get face embedding\n",
    "netArc = iresnet100(fp16=False)\n",
    "netArc.load_state_dict(torch.load('arcface_model/backbone.pth'))\n",
    "netArc=netArc.cuda()\n",
    "netArc.eval()\n",
    "\n",
    "# model to get face landmarks\n",
    "handler = Handler('./coordinate_reg/model/2d106det', 0, ctx_id=0, det_size=640)\n",
    "\n",
    "# model to make superres of face, set use_sr=True if you want to use super resolution or use_sr=False if you don't\n",
    "use_sr = True\n",
    "if use_sr:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    opt = TestOptions()\n",
    "    #opt.which_epoch ='10_7'\n",
    "    model = Pix2PixModel(opt)\n",
    "    model.netG.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occasional-hanging",
   "metadata": {},
   "source": [
    "### Set here path to source image and video for faceswap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d613e79",
   "metadata": {},
   "source": [
    "# 특징 빼기 + 인젝션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0d599af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.inference.faceshifter_run import faceshifter_batch\n",
    "from utils.inference.image_processing import crop_face, normalize_and_torch, normalize_and_torch_batch\n",
    "from utils.inference.video_processing import read_video, crop_frames_and_get_transforms, resize_frames\n",
    "from utils.inference.core import transform_target_to_torch\n",
    "\n",
    "image_to_image = True\n",
    "\n",
    "set_target = False\n",
    "half=True\n",
    "similarity_th=0.15\n",
    "\n",
    "crop_size = 224 # don't change this\n",
    "BS = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f12e1f",
   "metadata": {},
   "source": [
    "# pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66534486",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./pca_pkl/netArcPCA.pkl\", \"rb\") as file:\n",
    "    pca = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5c5d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from insightface.utils import face_align\n",
    "import ipywidgets as widgets\n",
    "\n",
    "set_target = False\n",
    "half=True\n",
    "similarity_th=0.15\n",
    "\n",
    "crop_frames_list = None\n",
    "target_batch_rs = None\n",
    "start_id = 0\n",
    "tmp_embed = [np.load(\"./examples/arc_embeds/VggFace2-crop/{}.npy\".format(start_id))]\n",
    "pca_array = pca.transform(tmp_embed)\n",
    "with open(\"./pca_pkl/netArcPCAMinMax.pkl\", \"rb\") as file:\n",
    "    pca_minmax = pickle.load(file)\n",
    "pca_min = pca_minmax[\"min\"]\n",
    "pca_max = pca_minmax[\"max\"]\n",
    "\n",
    "def load_target(path_to_target='examples/images/tgt1.jpg'):\n",
    "    global crop_frames_list, target_batch_rs\n",
    "    target_full = cv2.imread(path_to_target)\n",
    "    full_frames = [target_full]\n",
    "    target = get_target(full_frames, app, crop_size)\n",
    "\n",
    "    target_norm = normalize_and_torch_batch(np.array(target))\n",
    "    target_embeds = netArc(F.interpolate(target_norm, scale_factor=0.5, mode='bilinear', align_corners=True))\n",
    "\n",
    "    # Get the cropped faces from original frames and transformations to get those crops\n",
    "    crop_frames_list, tfm_array_list = crop_frames_and_get_transforms(full_frames,\n",
    "                                                                    target_embeds,\n",
    "                                                                    app,\n",
    "                                                                    netArc,\n",
    "                                                                    crop_size,\n",
    "                                                                    set_target,\n",
    "                                                                    similarity_th=similarity_th\n",
    "                                                                    )\n",
    "    resized_frs, present = resize_frames(crop_frames_list[0])\n",
    "    resized_frs = np.array(resized_frs)\n",
    "\n",
    "    target_batch_rs = transform_target_to_torch(resized_frs, half=True)\n",
    "\n",
    "\n",
    "load_target()\n",
    "\n",
    "\n",
    "def inject_drawing():\n",
    "    global crop_frames_list, pca_array\n",
    "    plt.figure(num=1, clear=True, figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(crop_frames_list[0][0][:,:,::-1])\n",
    "    plt.title(\"Target Face\")\n",
    "    plt.subplot(1, 2, 2)\n",
    "\n",
    "    modified_embed = pca.inverse_transform(pca_array)\n",
    "\n",
    "    source_embed = torch.from_numpy(modified_embed).half().to(\"cuda\")\n",
    "    #source_embed[0][0] = 10.0\n",
    "\n",
    "    Y_st = faceshifter_batch(source_embed, target_batch_rs, G)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    plt.imshow(Y_st[0][:, :, ::-1])\n",
    "    plt.title(\"After Swap\")\n",
    "    plt.show()\n",
    "\n",
    "pca_sliders = []\n",
    "\n",
    "iact_plot = widgets.interactive(\n",
    "    inject_drawing\n",
    ")\n",
    "\n",
    "for i in range(40):\n",
    "    pca_slider = widgets.FloatSlider(\n",
    "        value=pca_array[0, i], \n",
    "        min = pca_min[i],\n",
    "        max = pca_max[i],\n",
    "        description=f\"PCA #{i}\",\n",
    "        continuous_update=False,\n",
    "        layout=widgets.Layout(width=\"300px\"),\n",
    "    )\n",
    "    pca_slider.idx = i\n",
    "    pca_slider.observe(lambda change: exec(\"pca_array[0, change.owner.idx]=change.new;iact_plot.update()\"), names=\"value\")\n",
    "    #pca_slider.observe(lambda change: print(change.owner.idx), names=\"value\")\n",
    "    pca_sliders.append(pca_slider)\n",
    "    \n",
    "\n",
    "slider_multibox = widgets.HBox(\n",
    "    children=[\n",
    "    widgets.VBox(\n",
    "    children = pca_sliders[:20]),\n",
    "    widgets.VBox(\n",
    "    children = pca_sliders[20:]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "display(iact_plot, slider_multibox)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5fc7da",
   "metadata": {},
   "source": [
    "# PCA 값에 따른 변화 그림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73efa0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_save_dir = \"./pca_figs\"\n",
    "os.makedirs(fig_save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "set_target = False\n",
    "half=True\n",
    "similarity_th=0.15\n",
    "crop_frames_list = None\n",
    "target_batch_rs = None\n",
    "\n",
    "with open(\"./pca_pkl/netArcPCA.pkl\", \"rb\") as file:\n",
    "    pca = pickle.load(file)\n",
    "\n",
    "with open(\"./pca_pkl/netArcPCAMinMax.pkl\", \"rb\") as file:\n",
    "    pca_minmax = pickle.load(file)\n",
    "pca_min = pca_minmax[\"min\"]\n",
    "pca_max = pca_minmax[\"max\"]\n",
    "\n",
    "start_id = 0\n",
    "#tmp_embed = [np.load(\"./examples/arc_embeds/VggFace2-crop/{}.npy\".format(start_id))]\n",
    "#pca_array = pca.transform(tmp_embed)\n",
    "\n",
    "tmp_embed = [((0.3+0.7*np.random.random(pca_min.shape[0]))*(pca_max-pca_min)+pca_min)]\n",
    "#tmp_embed = [(pca_min+pca_max)/2]\n",
    "pca_array = pca.transform(tmp_embed)\n",
    "\n",
    "\n",
    "def load_target(path_to_target='examples/images/tgt1.png'):\n",
    "    global crop_frames_list, target_batch_rs\n",
    "    target_full = cv2.imread(path_to_target)\n",
    "    full_frames = [target_full]\n",
    "    target = get_target(full_frames, app, crop_size)\n",
    "\n",
    "    target_norm = normalize_and_torch_batch(np.array(target))\n",
    "    target_embeds = netArc(F.interpolate(target_norm, scale_factor=0.5, mode='bilinear', align_corners=True))\n",
    "\n",
    "    # Get the cropped faces from original frames and transformations to get those crops\n",
    "    crop_frames_list, tfm_array_list = crop_frames_and_get_transforms(full_frames,\n",
    "                                                                    target_embeds,\n",
    "                                                                    app,\n",
    "                                                                    netArc,\n",
    "                                                                    crop_size,\n",
    "                                                                    set_target,\n",
    "                                                                    similarity_th=similarity_th\n",
    "                                                                    )\n",
    "    resized_frs, present = resize_frames(crop_frames_list[0])\n",
    "    resized_frs = np.array(resized_frs)\n",
    "\n",
    "    target_batch_rs = transform_target_to_torch(resized_frs, half=True)\n",
    "\n",
    "\n",
    "load_target()\n",
    "\n",
    "num_plotted_pca = 40\n",
    "n_ticks = 5\n",
    "\n",
    "plt.figure(num=1, clear=True, figsize=(n_ticks*2, num_plotted_pca*2))\n",
    "plt.subplot(num_plotted_pca+1,n_ticks, 1)\n",
    "plt.imshow(crop_frames_list[0][0][:,:,::-1])\n",
    "plt.title(\"Target Face\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(num_plotted_pca+1,n_ticks,2)\n",
    "\n",
    "modified_embed = pca.inverse_transform(pca_array)\n",
    "\n",
    "source_embed = torch.from_numpy(modified_embed).half().to(\"cuda\")\n",
    "#source_embed[0][0] = 10.0\n",
    "\n",
    "Y_st = faceshifter_batch(source_embed, target_batch_rs, G)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "plt.imshow(Y_st[0][:, :, ::-1])\n",
    "plt.title(\"Swapped (Random)\")\n",
    "#plt.axis(\"off\")\n",
    "for side in [\"top\", \"right\", \"bottom\", \"left\"]: plt.gca().spines[side].set_visible(False)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "\n",
    "\n",
    "for pci_i in range(num_plotted_pca):\n",
    "    interval = (pca_max[pci_i] - pca_min[pci_i]) / (n_ticks-1)\n",
    "    for c in range(n_ticks):\n",
    "        plt.subplot(num_plotted_pca+1,n_ticks, (pci_i+1)*n_ticks+c+1)\n",
    "        new_pca_array = pca_array.copy()\n",
    "        new_pca_array[0, pci_i] = pca_min[pci_i] + (interval * c)\n",
    "        modified_embed = pca.inverse_transform(new_pca_array)\n",
    "\n",
    "        source_embed = torch.from_numpy(modified_embed).half().to(\"cuda\")\n",
    "        #source_embed[0][0] = 10.0\n",
    "\n",
    "        Y_st = faceshifter_batch(source_embed, target_batch_rs, G)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        plt.imshow(Y_st[0][:, :, ::-1])\n",
    "        #plt.title(\"Swapped Face \")\n",
    "        #plt.axis(\"off\")\n",
    "        for side in [\"top\", \"right\", \"bottom\", \"left\"]: plt.gca().spines[side].set_visible(False)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.xlabel(f\"{new_pca_array[0, pci_i]:.2f}\")\n",
    "\n",
    "        if c == 0:\n",
    "            plt.ylabel(\"PCA #{}\".format(pci_i))\n",
    "\n",
    "plt.tight_layout()\n",
    "save_path = f\"{fig_save_dir}/PCA_for_arc_embed_to{num_plotted_pca}.png\"\n",
    "plt.savefig(save_path)\n",
    "plt.close()\n",
    "print(f\"saved at {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for comparison\n",
    "tgt1_path = \"./examples/images/tgt1.png\"\n",
    "tgt2_path = \"./examples/images/elon_musk.jpg\"\n",
    "tgt3_path = \"./examples/images/tgt2.png\"\n",
    "\n",
    "\n",
    "set_target = False\n",
    "half=True\n",
    "similarity_th=0.15\n",
    "crop_size = 224 # don't change this\n",
    "BS = 60\n",
    "\n",
    "\n",
    "crop_frames_list = None\n",
    "target_batch_rs = None\n",
    "with open(\"./pca_pkl/netArcPCA.pkl\", \"rb\") as file:\n",
    "    pca = pickle.load(file)\n",
    "\n",
    "with open(\"./pca_pkl/netArcPCAMinMax.pkl\", \"rb\") as file:\n",
    "    pca_minmax = pickle.load(file)\n",
    "pca_min = pca_minmax[\"min\"]\n",
    "pca_max = pca_minmax[\"max\"]\n",
    "\n",
    "start_id = 0\n",
    "#tmp_embed = [np.load(\"./embeds/{}.npy\".format(start_id))]\n",
    "#pca_array = pca.transform(tmp_embed)\n",
    "\n",
    "tmp_embed = [((0.4+0.6*np.random.random(pca_min.shape[0]))*(pca_max-pca_min)+pca_min)]\n",
    "#tmp_embed = [(pca_min+pca_max)/2]\n",
    "pca_array = pca.transform(tmp_embed)\n",
    "\n",
    "\n",
    "def load_target(path_to_target='examples/images/tgt1.png'):\n",
    "    global crop_frames_list, target_batch_rs\n",
    "    target_full = cv2.imread(path_to_target)\n",
    "    full_frames = [target_full]\n",
    "    target = get_target(full_frames, app, crop_size)\n",
    "\n",
    "    target_norm = normalize_and_torch_batch(np.array(target))\n",
    "    target_embeds = netArc(F.interpolate(target_norm, scale_factor=0.5, mode='bilinear', align_corners=True))\n",
    "\n",
    "    # Get the cropped faces from original frames and transformations to get those crops\n",
    "    crop_frames_list, tfm_array_list = crop_frames_and_get_transforms(full_frames,\n",
    "                                                                    target_embeds,\n",
    "                                                                    app,\n",
    "                                                                    netArc,\n",
    "                                                                    crop_size,\n",
    "                                                                    set_target,\n",
    "                                                                    similarity_th=similarity_th\n",
    "                                                                    )\n",
    "    resized_frs, present = resize_frames(crop_frames_list[0])\n",
    "    resized_frs = np.array(resized_frs)\n",
    "\n",
    "    target_batch_rs = transform_target_to_torch(resized_frs, half=True)\n",
    "\n",
    "\n",
    "load_target(path_to_target=\"examples/images/tgt1.png\")\n",
    "\n",
    "num_plotted_pca = 20\n",
    "n_ticks = 7\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(num=1, clear=True, figsize=(n_ticks*2, (num_plotted_pca*3+1)*2))\n",
    "\n",
    "def draw_top(subplot_tuple, img):\n",
    "    plt.subplot(*subplot_tuple)\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Target Face\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "\n",
    "def draw_swap(subplot_tuple, pca_embed, is_top=False):\n",
    "    global target_batch_rs, G\n",
    "    plt.subplot(*subplot_tuple)\n",
    "\n",
    "    modified_embed = pca.inverse_transform(pca_embed)\n",
    "    source_embed = torch.from_numpy(modified_embed).half().to(\"cuda\")\n",
    "\n",
    "    Y_st = faceshifter_batch(source_embed, target_batch_rs, G)\n",
    "    torch.cuda.empty_cache()\n",
    "    plt.imshow(Y_st[0][:, :, ::-1])\n",
    "    \n",
    "    for side in [\"top\", \"right\", \"bottom\", \"left\"]: plt.gca().spines[side].set_visible(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if is_top:\n",
    "        plt.title(\"Swapped (Random)\")\n",
    "\n",
    "\n",
    "load_target(path_to_target=tgt1_path)\n",
    "draw_top((num_plotted_pca*3+1, n_ticks, 1), crop_frames_list[0][0][:,:,::-1])\n",
    "draw_swap((num_plotted_pca*3+1, n_ticks, 2), pca_array, is_top=True)\n",
    "\n",
    "load_target(path_to_target=tgt2_path)\n",
    "draw_top((num_plotted_pca*3+1, n_ticks, 3), crop_frames_list[0][0][:,:,::-1])\n",
    "draw_swap((num_plotted_pca*3+1, n_ticks, 4), pca_array, is_top=True)\n",
    "\n",
    "load_target(path_to_target=tgt3_path)\n",
    "draw_top((num_plotted_pca*3+1, n_ticks, 5), crop_frames_list[0][0][:,:,::-1])\n",
    "draw_swap((num_plotted_pca*3+1, n_ticks, 6), pca_array, is_top=True)\n",
    "\n",
    "for pci_i in range(num_plotted_pca):\n",
    "    interval = (pca_max[pci_i] - pca_min[pci_i]) / (n_ticks-1)\n",
    "    for c in range(n_ticks):\n",
    "        new_pca_array = pca_array.copy()\n",
    "        new_pca_array[0, pci_i] = pca_min[pci_i] + (interval * c)\n",
    "        \n",
    "        load_target(tgt1_path)\n",
    "        draw_swap((num_plotted_pca*3+1, n_ticks, (pci_i*3+1)*n_ticks+c+1), new_pca_array)\n",
    "        plt.xlabel(f\"{new_pca_array[0, pci_i]:.2f}\")\n",
    "        if c == 0:\n",
    "            plt.ylabel(\"PCA #{}\".format(pci_i))\n",
    "        load_target(tgt2_path)\n",
    "        draw_swap((num_plotted_pca*3+1, n_ticks, (pci_i*3+2)*n_ticks+c+1), new_pca_array)\n",
    "        plt.xlabel(f\"{new_pca_array[0, pci_i]:.2f}\")\n",
    "        if c == 0:\n",
    "            plt.ylabel(\"PCA #{}\".format(pci_i))\n",
    "        load_target(tgt3_path)\n",
    "        draw_swap((num_plotted_pca*3+1, n_ticks, (pci_i*3+3)*n_ticks+c+1), new_pca_array)\n",
    "        plt.xlabel(f\"{new_pca_array[0, pci_i]:.2f}\")\n",
    "        if c == 0:\n",
    "            plt.ylabel(\"PCA #{}\".format(pci_i))\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "save_path = f\"{fig_save_dir}/PCA_for_arc_embed_Triple_to{num_plotted_pca}.png\"\n",
    "plt.savefig(save_path)\n",
    "plt.close()\n",
    "print(f\"saved at {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xaiseung_ghost_cuda114",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
