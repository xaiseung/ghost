{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 코드 설명 (임시)\n",
    "\n",
    "- GAN Generator의 중간값 뽑아서 저장해놓는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "published-metro",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/kornia/augmentation/augmentation.py:1830: DeprecationWarning: GaussianBlur is no longer maintained and will be removed from the future versions. Please use RandomGaussianBlur instead.\n",
      "  warnings.warn(\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/mxnet/numpy/fallback.py:143: DeprecationWarning: In accordance with NEP 32, the function mirr was removed from NumPy version 1.20.  A replacement for this function is available in the numpy_financial library: https://pypi.org/project/numpy-financial\n",
      "  mirr = onp.mirr\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/mxnet/numpy/fallback.py:160: DeprecationWarning: In accordance with NEP 32, the function npv was removed from NumPy version 1.20.  A replacement for this function is available in the numpy_financial library: https://pypi.org/project/numpy-financial\n",
      "  npv = onp.npv\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/mxnet/numpy/fallback.py:164: DeprecationWarning: In accordance with NEP 32, the function pmt was removed from NumPy version 1.20.  A replacement for this function is available in the numpy_financial library: https://pypi.org/project/numpy-financial\n",
      "  pmt = onp.pmt\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/mxnet/numpy/fallback.py:173: DeprecationWarning: In accordance with NEP 32, the function ppmt was removed from NumPy version 1.20.  A replacement for this function is available in the numpy_financial library: https://pypi.org/project/numpy-financial\n",
      "  ppmt = onp.ppmt\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/mxnet/numpy/fallback.py:176: DeprecationWarning: In accordance with NEP 32, the function pv was removed from NumPy version 1.20.  A replacement for this function is available in the numpy_financial library: https://pypi.org/project/numpy-financial\n",
      "  pv = onp.pv\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/mxnet/numpy/fallback.py:177: DeprecationWarning: In accordance with NEP 32, the function rate was removed from NumPy version 1.20.  A replacement for this function is available in the numpy_financial library: https://pypi.org/project/numpy-financial\n",
      "  rate = onp.rate\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/mxnet/numpy_dispatch_protocol.py:48: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  cur_np_ver = LooseVersion(_np.__version__)\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/mxnet/numpy_dispatch_protocol.py:49: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  np_1_17_ver = LooseVersion('1.17')\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/mxnet/numpy_dispatch_protocol.py:68: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  cur_np_ver = LooseVersion(_np.__version__)\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/mxnet/numpy_dispatch_protocol.py:69: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  np_1_15_ver = LooseVersion('1.15')\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "def nop(it, *a, **k):\n",
    "    return it\n",
    "\n",
    "real_tqdm = tqdm.tqdm\n",
    "tqdm.tqdm = nop\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "np.bool = np.bool_\n",
    "\n",
    "from utils.inference.image_processing import crop_face, get_final_image, show_images\n",
    "from utils.inference.video_processing import read_video, get_target, get_final_video, add_audio_from_another_video, face_enhancement\n",
    "from utils.inference.core import model_inference\n",
    "\n",
    "from network.AEI_Net import AEI_Net\n",
    "from coordinate_reg.image_infer import Handler\n",
    "from insightface_func.face_detect_crop_multi import Face_detect_crop\n",
    "from arcface_model.iresnet import iresnet100\n",
    "from models.pix2pix_model import Pix2PixModel\n",
    "from models.config_sr import TestOptions\n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-factor",
   "metadata": {},
   "source": [
    "### Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "signed-mustang",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input mean and std: 127.5 127.5\n",
      "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
      "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
      "set det-size: (640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ./coordinate_reg/model/2d106det 0\n",
      "input mean and std: 127.5 127.5\n",
      "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
      "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
      "set det-size: (640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[06:15:45] ../src/nnvm/legacy_json_util.cc:208: Loading symbol saved by previous version v1.5.0. Attempting to upgrade...\n",
      "[06:15:45] ../src/nnvm/legacy_json_util.cc:216: Symbol successfully upgraded!\n",
      "[06:15:45] ../src/base.cc:79: cuDNN lib mismatch: linked-against version 8204 != compiled-against version 8101.  Set MXNET_CUDNN_LIB_CHECKING=0 to quiet this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network [LIPSPADEGenerator] was created. Total number of parameters: 72.2 million. To see the architecture, do print(network).\n",
      "Load checkpoint from path:  weights/10_net_G.pth\n"
     ]
    }
   ],
   "source": [
    "app = Face_detect_crop(name='antelope', root='./insightface_func/models')\n",
    "app.prepare(ctx_id= 0, det_thresh=0.6, det_size=(640,640))\n",
    "\n",
    "# main model for generation\n",
    "G = AEI_Net(backbone='unet', num_blocks=2, c_id=512)\n",
    "G.eval()\n",
    "G.load_state_dict(torch.load('weights/G_unet_2blocks.pth', map_location=torch.device('cpu')))\n",
    "G = G.cuda()\n",
    "G = G.half()\n",
    "\n",
    "# arcface model to get face embedding\n",
    "netArc = iresnet100(fp16=False)\n",
    "netArc.load_state_dict(torch.load('arcface_model/backbone.pth'))\n",
    "netArc=netArc.cuda()\n",
    "netArc.eval()\n",
    "\n",
    "# model to get face landmarks\n",
    "handler = Handler('./coordinate_reg/model/2d106det', 0, ctx_id=0, det_size=640)\n",
    "\n",
    "# model to make superres of face, set use_sr=True if you want to use super resolution or use_sr=False if you don't\n",
    "use_sr = True\n",
    "if use_sr:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    opt = TestOptions()\n",
    "    #opt.which_epoch ='10_7'\n",
    "    model = Pix2PixModel(opt)\n",
    "    model.netG.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d613e79",
   "metadata": {},
   "source": [
    "# 중간계층값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8631/8631 [25:23<00:00,  5.67it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from utils.inference.faceshifter_run import faceshifter_batch\n",
    "from utils.inference.image_processing import crop_face, normalize_and_torch, normalize_and_torch_batch\n",
    "from utils.inference.video_processing import read_video, crop_frames_and_get_transforms, resize_frames\n",
    "from utils.inference.core import transform_target_to_torch\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "set_target = False\n",
    "half=True\n",
    "similarity_th=0.15\n",
    "crop_size = 224 # don't change this\n",
    "BS = 60\n",
    "\n",
    "save_dir = \"./examples/z_embeds/VggFace2-crop\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "np.random.seed(7777)\n",
    "\n",
    "id_folder_list = glob.glob(\"./examples/images/VggFace2-crop/*\")\n",
    "id_folder_list.sort()\n",
    "with open(f\"{save_dir}/VggFace2-cropzattr_embed_list.txt\", \"w\") as embed_log:\n",
    "    output_cnt = 0\n",
    "    for id_folder in real_tqdm(id_folder_list):\n",
    "        pics = glob.glob(id_folder+\"/*.jpg\")\n",
    "        pics.sort()\n",
    "        np.random.shuffle(pics)\n",
    "        for pic in pics[:2]:\n",
    "            source_full = cv2.imread(pic)\n",
    "            full_frames = [source_full]\n",
    "            #print(source_full.shape)\n",
    "            #source = crop_face(source_full, app, crop_size)[0]\n",
    "            # 버그 수정. target은 bgr 형태로 입력이 되어야 함\n",
    "            source_curr = cv2.resize(source_full, (crop_size, crop_size))\n",
    "            target = [source_curr.copy()]\n",
    "            source_curr = normalize_and_torch(source_curr[:,:,::-1])\n",
    "            #print(source_curr.shape)\n",
    "            source_embed = netArc(F.interpolate(source_curr, scale_factor=0.5, mode='bilinear', align_corners=True))\n",
    "\n",
    "\n",
    "            #get_target(full_frames, app, crop_size)\n",
    "            target_norm = normalize_and_torch_batch(np.array(target))\n",
    "\n",
    "            target_embeds = netArc(F.interpolate(target_norm, scale_factor=0.5, mode='bilinear', align_corners=True))\n",
    "\n",
    "            # Get the cropped faces from original frames and transformations to get those crops\n",
    "            #crop_frames_list, tfm_array_list = crop_frames_and_get_transforms(full_frames, target_embeds, app, netArc, crop_size, set_target, similarity_th=similarity_th)\n",
    "            #crop_frames = crop_frames_list[0]\n",
    "\n",
    "            crop_frames = target\n",
    "            resized_frs, present = resize_frames(crop_frames)\n",
    "            resized_frs = np.array(resized_frs)\n",
    "\n",
    "\n",
    "            target_batch_rs = transform_target_to_torch(resized_frs, half=half)\n",
    "            #assert False\n",
    "            if half:\n",
    "                source_embed = source_embed.half()\n",
    "            \n",
    "            bs = target_batch_rs.shape[0]\n",
    "            source_emb = torch.cat([source_embed]*bs)\n",
    "            \n",
    "            #Y_st = faceshifter_batch(source_embed, target_batch_rs, G)\n",
    "            Y_st, zattrs = G(target_batch_rs, source_emb)\n",
    "            zattrs = list(zattrs)\n",
    "            for i in range(len(zattrs)):\n",
    "                zattrs[i] = zattrs[i].detach().cpu().numpy()\n",
    "            #print(source_embed.shape)\n",
    "\n",
    "            with open(f\"{save_dir}/{output_cnt:d}.pkl\", \"wb\") as file:\n",
    "                pickle.dump(zattrs, file)\n",
    "            embed_log.write(pic+\"\\n\")\n",
    "            #assert False\n",
    "            output_cnt += 1\n",
    "            #if output_cnt >= 10:\n",
    "            #    assert False;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xaiseung_ghost_cuda114",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
