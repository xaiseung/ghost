{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-metro",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "np.bool = np.bool_\n",
    "\n",
    "from utils.inference.image_processing import crop_face, get_final_image, show_images\n",
    "from utils.inference.video_processing import read_video, get_target, get_final_video, add_audio_from_another_video, face_enhancement\n",
    "from utils.inference.core import model_inference\n",
    "\n",
    "from network.AEI_Net import AEI_Net\n",
    "from coordinate_reg.image_infer import Handler\n",
    "from insightface_func.face_detect_crop_multi import Face_detect_crop\n",
    "from arcface_model.iresnet import iresnet100\n",
    "from models.pix2pix_model import Pix2PixModel\n",
    "from models.config_sr import TestOptions\n",
    "\n",
    "\n",
    "use_sr = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "app = Face_detect_crop(name='antelope', root='./insightface_func/models')\n",
    "app.prepare(ctx_id= 0, det_thresh=0.6, det_size=(640,640))\n",
    "\n",
    "# main model for generation\n",
    "G = AEI_Net(backbone='unet', num_blocks=2, c_id=512)\n",
    "G.eval()\n",
    "G.load_state_dict(torch.load('weights/G_unet_2blocks.pth', map_location=torch.device('cpu')))\n",
    "G = G.cuda()\n",
    "G = G.half()\n",
    "\n",
    "# arcface model to get face embedding\n",
    "netArc = iresnet100(fp16=False)\n",
    "netArc.load_state_dict(torch.load('arcface_model/backbone.pth'))\n",
    "netArc=netArc.cuda()\n",
    "netArc.eval()\n",
    "\n",
    "# model to get face landmarks\n",
    "handler = Handler('./coordinate_reg/model/2d106det', 0, ctx_id=0, det_size=640)\n",
    "\n",
    "# model to make superres of face, set use_sr=True if you want to use super resolution or use_sr=False if you don't\n",
    "if use_sr:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    opt = TestOptions()\n",
    "    #opt.which_epoch ='10_7'\n",
    "    model = Pix2PixModel(opt)\n",
    "    model.netG.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bb9595",
   "metadata": {},
   "source": [
    "# Easy Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e35d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_face(source: str,\n",
    "              target: str,\n",
    "              output_path: str,\n",
    "              image_to_image=True,\n",
    "              show_image=True,\n",
    "              with_audio=False):\n",
    "    \"\"\"\n",
    "    choose not really long videos, coz it can take a lot of time othervise \n",
    "    choose source image as a photo -- preferable a selfie of a person\n",
    "    \"\"\"\n",
    "    if image_to_image:\n",
    "        path_to_target = target\n",
    "    else:\n",
    "        path_to_video = target\n",
    "    #source_full = cv2.imread('examples/images/elon_musk.jpg')\n",
    "    source_full = cv2.imread(source)\n",
    "    \n",
    "    OUTPUT_NAME = output_path+f\"/{os.path.splitext(os.path.basename(source))[0]}_{os.path.splitext(os.path.basename(target))[0]}\"\n",
    "    \n",
    "    crop_size = 224 # don't change this\n",
    "    BS = 60\n",
    "\n",
    "    try:    \n",
    "        source = crop_face(source_full, app, crop_size)[0]\n",
    "        source = [source[:, :, ::-1]]\n",
    "        print(\"Everything is ok!\")\n",
    "    except TypeError:\n",
    "        print(\"Bad source images\")\n",
    "        return\n",
    "\n",
    "\n",
    "    if image_to_image:\n",
    "        target_full = cv2.imread(path_to_target)\n",
    "        full_frames = [target_full]\n",
    "        \n",
    "    else:\n",
    "        full_frames, fps = read_video(path_to_video)\n",
    "    target = get_target(full_frames, app, crop_size)\n",
    "    if type(target) == type(None) or len(target) == 0:\n",
    "        print(\"no face detected in targe image/video\")\n",
    "        return\n",
    "    \n",
    "    final_frames_list, crop_frames_list, full_frames, tfm_array_list = model_inference(full_frames,\n",
    "                                                                                    source,\n",
    "                                                                                    target,\n",
    "                                                                                    netArc,\n",
    "                                                                                    G,\n",
    "                                                                                    app,\n",
    "                                                                                    set_target = False,\n",
    "                                                                                    crop_size=crop_size,\n",
    "                                                                                    BS=BS)\n",
    "\n",
    "    if use_sr:\n",
    "        final_frames_list = face_enhancement(final_frames_list, model)\n",
    "\n",
    "    if image_to_image:\n",
    "        result = get_final_image(final_frames_list, crop_frames_list, full_frames[0], tfm_array_list, handler)\n",
    "        if show_image:\n",
    "            show_images([source[0][:, :, ::-1], target_full, result], ['Source Image', 'Target Image', 'Swapped Image'], figsize=(20, 15))\n",
    "        cv2.imwrite(f\"{OUTPUT_NAME}.jpg\", result)\n",
    "        \n",
    "    else:\n",
    "        get_final_video(final_frames_list,\n",
    "                        crop_frames_list,\n",
    "                        full_frames,\n",
    "                        tfm_array_list,\n",
    "                        OUTPUT_NAME+\".mp4\",\n",
    "                        fps, \n",
    "                        handler)\n",
    "        if with_audio:\n",
    "            add_audio_from_another_video(path_to_video, OUTPUT_NAME+\".mp4\", \"audio\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d250c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "swap_face(\"examples/images/IMG_1379.jpg\",\n",
    "          \"examples/images/beckham.jpg\",\n",
    "          \"examples/results\",\n",
    "          image_to_image=True,\n",
    "          show_image=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4077b17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "swap_face(\"examples/images/beckham.jpg\",\n",
    "          \"examples/videos/nggyup.mp4\",\n",
    "          \"examples/results\",\n",
    "          image_to_image=False,\n",
    "          with_audio=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xaiseung_ghost",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
