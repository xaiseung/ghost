{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "published-metro",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/kornia/augmentation/augmentation.py:1830: DeprecationWarning: GaussianBlur is no longer maintained and will be removed from the future versions. Please use RandomGaussianBlur instead.\n",
      "  warnings.warn(\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/mxnet/numpy/fallback.py:143: DeprecationWarning: In accordance with NEP 32, the function mirr was removed from NumPy version 1.20.  A replacement for this function is available in the numpy_financial library: https://pypi.org/project/numpy-financial\n",
      "  mirr = onp.mirr\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/mxnet/numpy/fallback.py:160: DeprecationWarning: In accordance with NEP 32, the function npv was removed from NumPy version 1.20.  A replacement for this function is available in the numpy_financial library: https://pypi.org/project/numpy-financial\n",
      "  npv = onp.npv\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/mxnet/numpy/fallback.py:164: DeprecationWarning: In accordance with NEP 32, the function pmt was removed from NumPy version 1.20.  A replacement for this function is available in the numpy_financial library: https://pypi.org/project/numpy-financial\n",
      "  pmt = onp.pmt\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/mxnet/numpy/fallback.py:173: DeprecationWarning: In accordance with NEP 32, the function ppmt was removed from NumPy version 1.20.  A replacement for this function is available in the numpy_financial library: https://pypi.org/project/numpy-financial\n",
      "  ppmt = onp.ppmt\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/mxnet/numpy/fallback.py:176: DeprecationWarning: In accordance with NEP 32, the function pv was removed from NumPy version 1.20.  A replacement for this function is available in the numpy_financial library: https://pypi.org/project/numpy-financial\n",
      "  pv = onp.pv\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/mxnet/numpy/fallback.py:177: DeprecationWarning: In accordance with NEP 32, the function rate was removed from NumPy version 1.20.  A replacement for this function is available in the numpy_financial library: https://pypi.org/project/numpy-financial\n",
      "  rate = onp.rate\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/mxnet/numpy_dispatch_protocol.py:48: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  cur_np_ver = LooseVersion(_np.__version__)\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/mxnet/numpy_dispatch_protocol.py:49: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  np_1_17_ver = LooseVersion('1.17')\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/mxnet/numpy_dispatch_protocol.py:68: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  cur_np_ver = LooseVersion(_np.__version__)\n",
      "/compuworks/anaconda3/envs/xaiseung_ghost_cuda114/lib/python3.9/site-packages/mxnet/numpy_dispatch_protocol.py:69: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  np_1_15_ver = LooseVersion('1.15')\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "def nop(it, *a, **k):\n",
    "    return it\n",
    "\n",
    "real_tqdm = tqdm.tqdm\n",
    "tqdm.tqdm = nop\n",
    "\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "np.bool = np.bool_\n",
    "import cv2\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils.inference.image_processing import crop_face, get_final_image, show_images, normalize_and_torch, normalize_and_torch_batch\n",
    "from utils.inference.video_processing import read_video, get_target, get_final_video, add_audio_from_another_video, face_enhancement, crop_frames_and_get_transforms, resize_frames\n",
    "from utils.inference.core import model_inference, transform_target_to_torch\n",
    "from utils.inference.faceshifter_run import faceshifter_batch, faceshifter_batch_zattrs\n",
    "from network.AEI_Net import AEI_Net\n",
    "from coordinate_reg.image_infer import Handler\n",
    "from insightface_func.face_detect_crop_multi import Face_detect_crop\n",
    "from arcface_model.iresnet import iresnet100\n",
    "from models.pix2pix_model import Pix2PixModel\n",
    "from models.config_sr import TestOptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-factor",
   "metadata": {},
   "source": [
    "### Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "signed-mustang",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input mean and std: 127.5 127.5\n",
      "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
      "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
      "set det-size: (640, 640)\n",
      "loading ./coordinate_reg/model/2d106det 0\n",
      "input mean and std: 127.5 127.5\n",
      "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
      "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
      "set det-size: (640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11:14:23] ../src/nnvm/legacy_json_util.cc:208: Loading symbol saved by previous version v1.5.0. Attempting to upgrade...\n",
      "[11:14:23] ../src/nnvm/legacy_json_util.cc:216: Symbol successfully upgraded!\n",
      "[11:14:23] ../src/base.cc:79: cuDNN lib mismatch: linked-against version 8204 != compiled-against version 8101.  Set MXNET_CUDNN_LIB_CHECKING=0 to quiet this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network [LIPSPADEGenerator] was created. Total number of parameters: 72.2 million. To see the architecture, do print(network).\n",
      "Load checkpoint from path:  weights/10_net_G.pth\n"
     ]
    }
   ],
   "source": [
    "app = Face_detect_crop(name='antelope', root='./insightface_func/models')\n",
    "app.prepare(ctx_id= 0, det_thresh=0.6, det_size=(640,640))\n",
    "\n",
    "# main model for generation\n",
    "G = AEI_Net(backbone='unet', num_blocks=2, c_id=512)\n",
    "G.eval()\n",
    "G.load_state_dict(torch.load('weights/G_unet_2blocks.pth', map_location=torch.device('cpu')))\n",
    "G = G.cuda()\n",
    "G = G.half()\n",
    "\n",
    "# arcface model to get face embedding\n",
    "netArc = iresnet100(fp16=False)\n",
    "netArc.load_state_dict(torch.load('arcface_model/backbone.pth'))\n",
    "netArc=netArc.cuda()\n",
    "netArc.eval()\n",
    "\n",
    "# model to get face landmarks\n",
    "handler = Handler('./coordinate_reg/model/2d106det', 0, ctx_id=0, det_size=640)\n",
    "\n",
    "# model to make superres of face, set use_sr=True if you want to use super resolution or use_sr=False if you don't\n",
    "use_sr = True\n",
    "if use_sr:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    opt = TestOptions()\n",
    "    #opt.which_epoch ='10_7'\n",
    "    model = Pix2PixModel(opt)\n",
    "    model.netG.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoublePCA:\n",
    "    def __init__(self, layer_num=8, root_path=\"./pca_pkl\"):\n",
    "        self.layer_num = layer_num\n",
    "\n",
    "        self.pca1_list = []\n",
    "        for z_i in range(self.layer_num):\n",
    "            with open(f\"{root_path}/Altered_zattr{z_i}PCA.pkl\", \"rb\") as file:\n",
    "                self.pca1_list.append(pickle.load(file))\n",
    "        with open(f\"{root_path}/Altered_zattr_doublePCA.pkl\", \"rb\") as file:\n",
    "            self.pca2 = pickle.load(file)\n",
    "        with open(f\"{root_path}/Altered_zattr_doublePCAMinMax.pkl\", \"rb\") as file:\n",
    "            minmax = pickle.load(file)\n",
    "        self.pca2_min = minmax[\"min\"]\n",
    "        self.pca2_max = minmax[\"max\"]\n",
    "    def transform(self, z_embeds):\n",
    "        p1emb_array = [self.pca1_list[z_i].transform(z_embeds[z_i]) for z_i in range(self.layer_num)]\n",
    "        p1emb_array = np.concatenate(p1emb_array, axis=1)\n",
    "        return self.pca2.transform(p1emb_array)\n",
    "    def inverse_transform(self, p2emb_array):\n",
    "        p1emb_array = self.pca2.inverse_transform(p2emb_array).reshape([-1, self.layer_num, 128])\n",
    "        z_embeds = [self.pca1_list[z_i].inverse_transform(p1emb_array[:,z_i]) for z_i in range(self.layer_num)]\n",
    "        return z_embeds\n",
    "    def calcul_z_embed_diff(self, target, original):\n",
    "        assert target.shape[0] == original.shape[0]\n",
    "        target = self.inverse_transform(target)\n",
    "        original = self.inverse_transform(original)\n",
    "        return [target[i]-original[i] for i in range(self.layer_num)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occasional-hanging",
   "metadata": {},
   "source": [
    "### Set here path to source image and video for faceswap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d613e79",
   "metadata": {},
   "source": [
    "# 특징 빼기 + 인젝션"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f12e1f",
   "metadata": {},
   "source": [
    "# pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad5c5d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b0a205aed2145a5a8ea6260c9315f95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Output(),), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a06e65b5a94b57bf28519d82582d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(FloatSlider(value=-38.73096453413527, continuous_update=False, description='PCA …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from insightface.utils import face_align\n",
    "import ipywidgets as widgets\n",
    "import copy\n",
    "\n",
    "crop_size = 224\n",
    "\n",
    "set_target = False\n",
    "half=True\n",
    "similarity_th=0.15\n",
    "\n",
    "crop_frames_list = None\n",
    "target_batch_rs = None\n",
    "image_to_image = True\n",
    "start_id = 50\n",
    "\n",
    "pca = DoublePCA()\n",
    "\n",
    "\n",
    "pca_min = pca.pca2_min\n",
    "pca_max = pca.pca2_max\n",
    "\n",
    "z_embed = None\n",
    "original_shape = None\n",
    "pca_array = None\n",
    "orig_z_embed = None\n",
    "original_pca = None\n",
    "\n",
    "def set_target(path_to_target='examples/images/jaeseung.jpg', image_to_image=True):\n",
    "    global z_embed, zattr_id, original_shape, pca_array, orig_z_embed, original_pca\n",
    "    if image_to_image:\n",
    "        target_full = cv2.imread(path_to_target)\n",
    "        full_frames = [target_full]\n",
    "    else:\n",
    "        full_frames, fps = read_video(path_to_video)\n",
    "    target = get_target(full_frames, app, crop_size)\n",
    "\n",
    "    target_norm = normalize_and_torch_batch(np.array(target))\n",
    "    target_embeds = netArc(F.interpolate(target_norm, scale_factor=0.5, mode='bilinear', align_corners=True))\n",
    "\n",
    "    # Get the cropped faces from original frames and transformations to get those crops\n",
    "    crop_frames_list, tfm_array_list = crop_frames_and_get_transforms(full_frames,\n",
    "                                                                    target_embeds,\n",
    "                                                                    app,\n",
    "                                                                    netArc,\n",
    "                                                                    crop_size,\n",
    "                                                                    set_target,\n",
    "                                                                    similarity_th=similarity_th\n",
    "                                                                    )\n",
    "    resized_frs, present = resize_frames(crop_frames_list[0])\n",
    "    resized_frs = np.array(resized_frs)\n",
    "\n",
    "    target_batch_rs = transform_target_to_torch(resized_frs, half=True)\n",
    "\n",
    "    zattrs = G.get_attr(target_batch_rs)\n",
    "    z_embed = list(zattrs)\n",
    "    original_shape = [attr.shape for attr in z_embed]\n",
    "\n",
    "    for i in range(len(z_embed)):\n",
    "        z_embed[i] = z_embed[i].detach().cpu().numpy().reshape(1, -1)\n",
    "    \n",
    "\n",
    "    original_pca = pca.transform(z_embed)\n",
    "    pca_array = original_pca.copy()\n",
    "    orig_z_embed = copy.deepcopy(z_embed)\n",
    "\n",
    "\n",
    "\n",
    "path_to_target=\"examples/images/elon_musk.jpg\"\n",
    "\n",
    "set_target(path_to_target)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "source_pic = \"examples/images/junseok.png\"\n",
    "\n",
    "source_full = cv2.imread(source_pic)\n",
    "full_frames = [source_full]\n",
    "source = crop_face(source_full, app, crop_size)[0][:,:,::-1]\n",
    "source_curr = source\n",
    "source_curr = normalize_and_torch(source_curr)\n",
    "source_embed = netArc(F.interpolate(source_curr, scale_factor=0.5, mode='bilinear', align_corners=True)).half()\n",
    "\n",
    "source_id = -1 if source_pic else 3\n",
    "if source_id >= 0: \n",
    "    source_embed = torch.from_numpy(np.array([np.load(\"./examples/arc_embeds/{}.npy\".format(source_id))])).half().to(\"cuda\")\n",
    "\n",
    "\n",
    "def inject_drawing():\n",
    "    global crop_frames_list, pca_array, z_embed, source_embed\n",
    "    plt.figure(num=1, clear=True, figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(cv2.imread(path_to_target)[:,:,::-1])\n",
    "    plt.title(\"Target Face\")\n",
    "    plt.subplot(1, 2, 2)\n",
    "\n",
    "    z_embed_diff = pca.calcul_z_embed_diff(pca_array, original_pca)\n",
    "    for zattr_id in range(len(z_embed)):\n",
    "        z_embed[zattr_id] = torch.from_numpy((orig_z_embed[zattr_id]+z_embed_diff[zattr_id]).reshape(*original_shape[zattr_id])).half().to(\"cuda\")\n",
    "    #source_embed[0][0] = 10.0\n",
    "\n",
    "    Y_st = faceshifter_batch_zattrs(source_embed, z_embed, 1, G)\n",
    "    #Y_st = faceshifter_batch(source_embed, target_batch_rs[i:i+BS], G)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    plt.imshow(Y_st[0][:,:,::-1])\n",
    "    plt.title(\"After Swap\")\n",
    "    plt.show()\n",
    "\n",
    "pca_sliders = []\n",
    "\n",
    "iact_plot = widgets.interactive(\n",
    "    inject_drawing\n",
    ")\n",
    "\n",
    "for i in range(40):\n",
    "    pca_slider = widgets.FloatSlider(\n",
    "        value=pca_array[0, i], \n",
    "        min = pca_min[i],\n",
    "        max = pca_max[i],\n",
    "        description=f\"PCA #{i}\",\n",
    "        continuous_update=False,\n",
    "        layout=widgets.Layout(width=\"300px\"),\n",
    "    )\n",
    "    pca_slider.idx = i\n",
    "    pca_slider.observe(lambda change: exec(\"pca_array[0, change.owner.idx]=change.new;iact_plot.update()\"), names=\"value\")\n",
    "    #pca_slider.observe(lambda change: print(change.owner.idx), names=\"value\")\n",
    "    pca_sliders.append(pca_slider)\n",
    "    \n",
    "\n",
    "slider_multibox = widgets.HBox(\n",
    "    children=[\n",
    "    widgets.VBox(\n",
    "    children = pca_sliders[:20]),\n",
    "    widgets.VBox(\n",
    "    children = pca_sliders[20:]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "display(iact_plot, slider_multibox)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5fc7da",
   "metadata": {},
   "source": [
    "# PCA 값에 따른 변화 그림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73efa0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved at ./pca_figs/doublePCA_for_zattr_tgt-1_to20_tmp.png\n"
     ]
    }
   ],
   "source": [
    "# 재미용\n",
    "\n",
    "\n",
    "pca = DoublePCA()\n",
    "pca_min = pca.pca2_min\n",
    "pca_max = pca.pca2_max\n",
    "pca_orig_range = pca_max - pca_min\n",
    "pca_min -= pca_orig_range*0.3\n",
    "pca_max += pca_orig_range*0.3\n",
    "\n",
    "set_target = False\n",
    "half=True\n",
    "similarity_th=0.15\n",
    "crop_size=224\n",
    "\n",
    "\n",
    "\n",
    "#start_id = 0\n",
    "#tmp_embed = [np.load(\"./embeds/{}.npy\".format(start_id))]\n",
    "#pca_array = pca.transform(tmp_embed)\n",
    "\n",
    "z_embed = None\n",
    "original_shape = None\n",
    "pca_array = None\n",
    "orig_z_embed = None\n",
    "original_pca = None\n",
    "\n",
    "def set_target(path_to_target='examples/images/jaeseung.jpg', image_to_image=True):\n",
    "    global z_embed, original_shape, pca_array, orig_z_embed, original_pca, full_frames\n",
    "    if image_to_image:\n",
    "        target_full = cv2.imread(path_to_target)\n",
    "        full_frames = [target_full]\n",
    "    else:\n",
    "        full_frames, fps = read_video(path_to_video)\n",
    "    target = get_target(full_frames, app, crop_size)\n",
    "\n",
    "    target_norm = normalize_and_torch_batch(np.array(target))\n",
    "    target_embeds = netArc(F.interpolate(target_norm, scale_factor=0.5, mode='bilinear', align_corners=True))\n",
    "\n",
    "    # Get the cropped faces from original frames and transformations to get those crops\n",
    "    crop_frames_list, tfm_array_list = crop_frames_and_get_transforms(full_frames,\n",
    "                                                                    target_embeds,\n",
    "                                                                    app,\n",
    "                                                                    netArc,\n",
    "                                                                    crop_size,\n",
    "                                                                    set_target,\n",
    "                                                                    similarity_th=similarity_th\n",
    "                                                                    )\n",
    "    resized_frs, present = resize_frames(crop_frames_list[0])\n",
    "    resized_frs = np.array(resized_frs)\n",
    "\n",
    "    target_batch_rs = transform_target_to_torch(resized_frs, half=True)\n",
    "\n",
    "    zattrs = G.get_attr(target_batch_rs)\n",
    "    z_embed = list(zattrs)\n",
    "    original_shape = [attr.shape for attr in z_embed]\n",
    "\n",
    "    for i in range(len(z_embed)):\n",
    "        z_embed[i] = z_embed[i].detach().cpu().numpy().reshape(1, -1)\n",
    "    \n",
    "\n",
    "    original_pca = pca.transform(z_embed)\n",
    "    pca_array = original_pca.copy()\n",
    "    orig_z_embed = copy.deepcopy(z_embed)\n",
    "\n",
    "\n",
    "\n",
    "set_target(path_to_target=\"examples/images/jaeseung_3.jpg\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "source_pic = \"examples/images/elon_musk.jpg\"\n",
    "\n",
    "source_full = cv2.imread(source_pic)\n",
    "source = crop_face(source_full, app, crop_size)[0][:,:,::-1]\n",
    "source_curr = source\n",
    "source_curr = normalize_and_torch(source_curr)\n",
    "source_embed = netArc(F.interpolate(source_curr, scale_factor=0.5, mode='bilinear', align_corners=True)).half()\n",
    "\n",
    "\n",
    "source_id = -1 if source_pic else 3\n",
    "#source_embed = torch.from_numpy(np.array([np.load(\"./examples/arc_embeds/{}.npy\".format(source_id))])).half().to(\"cuda\")\n",
    "\n",
    "num_plotted_pca = 20\n",
    "n_ticks = 5\n",
    "\n",
    "plt.figure(num=1, clear=True, figsize=(n_ticks*2, int((num_plotted_pca*3+1)*1.6)))\n",
    "\n",
    "\n",
    "plt.subplot(num_plotted_pca+1,n_ticks, 1)\n",
    "plt.imshow(cv2.imread(source_pic)[:,:,::-1])\n",
    "plt.title(\"Target Face\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(num_plotted_pca+1,n_ticks,2)\n",
    "\n",
    "tmp_z_embed = [torch.from_numpy(z_embed[i].reshape(original_shape[i])).half().to(\"cuda\") for i in range(len(z_embed))]\n",
    "\n",
    "Y_st = faceshifter_batch_zattrs(source_embed, tmp_z_embed, 1, G)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "plt.imshow(Y_st[0])\n",
    "plt.title(\"Swapped (origin)\")\n",
    "#plt.axis(\"off\")\n",
    "for side in [\"top\", \"right\", \"bottom\", \"left\"]: plt.gca().spines[side].set_visible(False)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "\n",
    "\n",
    "for pci_i in range(num_plotted_pca):\n",
    "    interval = (pca_max[pci_i] - pca_min[pci_i]) / (n_ticks-1)\n",
    "    for c in range(n_ticks):\n",
    "        plt.subplot(num_plotted_pca+1,n_ticks, (pci_i+1)*n_ticks+c+1)\n",
    "        new_pca_array = pca_array.copy()\n",
    "        new_pca_array[0, pci_i] = pca_min[pci_i] + (interval * c)\n",
    "\n",
    "        z_embed_diff = pca.calcul_z_embed_diff(new_pca_array, original_pca)\n",
    "        for zattr_id in range(len(z_embed)):\n",
    "            z_embed[zattr_id] = torch.from_numpy((orig_z_embed[zattr_id]+z_embed_diff[zattr_id]).reshape(*original_shape[zattr_id])).half().to(\"cuda\")\n",
    "        #source_embed[0][0] = 10.0\n",
    "\n",
    "        Y_st = faceshifter_batch_zattrs(source_embed, z_embed, 1, G)\n",
    "        #Y_st = faceshifter_batch(source_embed, target_batch_rs[i:i+BS], G)\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        plt.imshow(Y_st[0][:,:,::-1])\n",
    "        #plt.title(\"Swapped Face \")\n",
    "        #plt.axis(\"off\")\n",
    "        for side in [\"top\", \"right\", \"bottom\", \"left\"]: plt.gca().spines[side].set_visible(False)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.xlabel(f\"{new_pca_array[0, pci_i]:.2f}\")\n",
    "\n",
    "        if c == 0:\n",
    "            plt.ylabel(\"PCA #{}\".format(pci_i))\n",
    "\n",
    "plt.tight_layout()\n",
    "save_path = f\"./pca_figs/doublePCA_for_zattr_tgt{source_id}_to{num_plotted_pca}_tmp.png\"\n",
    "plt.savefig(save_path)\n",
    "plt.close()\n",
    "print(f\"saved at {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# zattr[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "set_target = False\n",
    "half=True\n",
    "similarity_th=0.15\n",
    "\n",
    "crop_frames_list = None\n",
    "target_batch_rs = None\n",
    "\n",
    "for zattr_id in [1, 2, 3, 4, 5, 6, 7]: \n",
    "\n",
    "    with open(f\"zattr{zattr_id}PCA.pkl\", \"rb\") as file:\n",
    "        pca = pickle.load(file)\n",
    "\n",
    "\n",
    "\n",
    "    with open(f\"zattr{zattr_id}PCAMinMax.pkl\", \"rb\") as file:\n",
    "        pca_minmax = pickle.load(file)\n",
    "    pca_min = pca_minmax[\"min\"]\n",
    "    pca_max = pca_minmax[\"max\"]\n",
    "    pca_orig_range = pca_max - pca_min\n",
    "    pca_min -= pca_orig_range*0.1\n",
    "    pca_max += pca_orig_range*0.1\n",
    "\n",
    "    #tmp_embed = [np.load(\"./embeds/{}.npy\".format(start_id))]\n",
    "    #pca_array = pca.transform(tmp_embed)\n",
    "\n",
    "    start_id = 10\n",
    "    with open(\"./examples/z_embeds/VggFace2-crop/{}.pkl\".format(start_id), \"rb\") as file:\n",
    "        z_embed = pickle.load(file)\n",
    "    original_shape = [attr.shape for attr in z_embed]\n",
    "    pca_array = pca.transform(z_embed[zattr_id].reshape(1, -1))\n",
    "    orig_z_embed = z_embed[zattr_id]\n",
    "    for i in range(len(z_embed)):\n",
    "        z_embed[i] = torch.from_numpy(z_embed[i]).half().to(\"cuda\")\n",
    "        \n",
    "    source_id = 3\n",
    "    source_embed = torch.from_numpy(np.array([np.load(\"./examples/arc_embeds/{}.npy\".format(source_id))])).half().to(\"cuda\")\n",
    "\n",
    "\n",
    "    num_plotted_pca = 40\n",
    "    n_ticks = 5\n",
    "\n",
    "    plt.figure(num=1, clear=True, figsize=(n_ticks*2, int(num_plotted_pca*1.75)) )\n",
    "    plt.subplot(num_plotted_pca+1,n_ticks, 1)\n",
    "    plt.imshow(cv2.imread(\"./examples/images/VggFace2-crop/n000007/0112_01.jpg\")[:,:,::-1])\n",
    "    plt.title(\"Target Face\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(num_plotted_pca+1,n_ticks,2)\n",
    "\n",
    "    Y_st = faceshifter_batch_zattrs(source_embed, z_embed, 1, G)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    plt.imshow(Y_st[0][:, :,])\n",
    "    plt.title(\"Swapped (origin)\")\n",
    "    #plt.axis(\"off\")\n",
    "    for side in [\"top\", \"right\", \"bottom\", \"left\"]: plt.gca().spines[side].set_visible(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "\n",
    "\n",
    "    for pci_i in range(num_plotted_pca):\n",
    "        interval = (pca_max[pci_i] - pca_min[pci_i]) / (n_ticks-1)\n",
    "        for c in range(n_ticks):\n",
    "            plt.subplot(num_plotted_pca+1,n_ticks, (pci_i+1)*n_ticks+c+1)\n",
    "            new_pca_array = pca_array.copy()\n",
    "            before_modi_embed = pca.inverse_transform(new_pca_array) \n",
    "            new_pca_array[0, pci_i] = pca_min[pci_i] + (interval * c)\n",
    "            modified_embed = pca.inverse_transform(new_pca_array)\n",
    "            embed_diff =  modified_embed - before_modi_embed\n",
    "            z_embed[zattr_id] = torch.from_numpy(orig_z_embed+embed_diff.reshape(*original_shape[zattr_id])).half().to(\"cuda\")\n",
    "            #source_embed[0][0] = 10.0\n",
    "\n",
    "            Y_st = faceshifter_batch_zattrs(source_embed, z_embed, 1, G)\n",
    "            #Y_st = faceshifter_batch(source_embed, target_batch_rs[i:i+BS], G)\n",
    "\n",
    "            plt.imshow(Y_st[0])\n",
    "            #plt.title(\"Swapped Face \")\n",
    "            #plt.axis(\"off\")\n",
    "            for side in [\"top\", \"right\", \"bottom\", \"left\"]: plt.gca().spines[side].set_visible(False)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.xlabel(f\"{new_pca_array[0, pci_i]:.2f}\")\n",
    "\n",
    "            if c == 0:\n",
    "                plt.ylabel(\"PCA #{}\".format(pci_i))\n",
    "\n",
    "    save_path = f\"./pca_figs/PCA_for_zattr[{zattr_id}]_tgt{source_id}_to{num_plotted_pca}.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"saved at {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved at ./pca_figs/doublePCA_for_zattr_src-1_Triple_to20_tmp.png\n"
     ]
    }
   ],
   "source": [
    "# for comparison\n",
    "\n",
    "set_target = False\n",
    "half=True\n",
    "similarity_th=0.15\n",
    "crop_size = 224 # don't change this\n",
    "BS = 60\n",
    "\n",
    "\n",
    "pca = DoublePCA()\n",
    "pca_min = pca.pca2_min\n",
    "pca_max = pca.pca2_max\n",
    "pca_orig_range = pca_max - pca_min\n",
    "pca_min -= pca_orig_range*0.3\n",
    "pca_max += pca_orig_range*0.3\n",
    "\n",
    "\n",
    "\n",
    "source_pic = \"examples/images/junseok.png\"\n",
    "\n",
    "source_full = cv2.imread(source_pic)\n",
    "full_frames = [source_full]\n",
    "source = crop_face(source_full, app, crop_size)[0][:,:,::-1]\n",
    "source_curr = source\n",
    "source_curr = normalize_and_torch(source_curr)\n",
    "source_embed = netArc(F.interpolate(source_curr, scale_factor=0.5, mode='bilinear', align_corners=True)).half()\n",
    "\n",
    "source_id = -1 if source_pic else 3\n",
    "if source_id >= 0: \n",
    "    source_embed = torch.from_numpy(np.array([np.load(\"./examples/arc_embeds/{}.npy\".format(source_id))])).half().to(\"cuda\")\n",
    "\n",
    "\n",
    "z_embed = None\n",
    "original_shape = None\n",
    "pca_array = None\n",
    "orig_z_embed = None\n",
    "original_pca = None\n",
    "crop_frames_list = None\n",
    "def set_target(path_to_target='examples/images/jaeseung.jpg', image_to_image=True):\n",
    "    global z_embed, zattr_id, original_shape, pca_array, orig_z_embed, original_pca, crop_frames_list\n",
    "    if image_to_image:\n",
    "        target_full = cv2.imread(path_to_target)\n",
    "        full_frames = [target_full]\n",
    "    else:\n",
    "        full_frames, fps = read_video(path_to_video)\n",
    "    target = get_target(full_frames, app, crop_size)\n",
    "\n",
    "    target_norm = normalize_and_torch_batch(np.array(target))\n",
    "    target_embeds = netArc(F.interpolate(target_norm, scale_factor=0.5, mode='bilinear', align_corners=True))\n",
    "\n",
    "    # Get the cropped faces from original frames and transformations to get those crops\n",
    "    crop_frames_list, tfm_array_list = crop_frames_and_get_transforms(full_frames,\n",
    "                                                                    target_embeds,\n",
    "                                                                    app,\n",
    "                                                                    netArc,\n",
    "                                                                    crop_size,\n",
    "                                                                    set_target,\n",
    "                                                                    similarity_th=similarity_th\n",
    "                                                                    )\n",
    "    resized_frs, present = resize_frames(crop_frames_list[0])\n",
    "    resized_frs = np.array(resized_frs)\n",
    "\n",
    "    target_batch_rs = transform_target_to_torch(resized_frs, half=True)\n",
    "\n",
    "    zattrs = G.get_attr(target_batch_rs)\n",
    "    z_embed = list(zattrs)\n",
    "    original_shape = [attr.shape for attr in z_embed]\n",
    "\n",
    "    for i in range(len(z_embed)):\n",
    "        z_embed[i] = z_embed[i].detach().cpu().numpy().reshape(1, -1)\n",
    "    \n",
    "\n",
    "    original_pca = pca.transform(z_embed)\n",
    "    pca_array = original_pca.copy()\n",
    "    orig_z_embed = copy.deepcopy(z_embed)\n",
    "\n",
    "\n",
    "set_target(path_to_target=\"examples/images/jaeseung.jpg\")\n",
    "\n",
    "num_plotted_pca = 20\n",
    "n_ticks = 7\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(num=1, clear=True, figsize=(n_ticks*2, int((num_plotted_pca*3+1)*1.6)) )\n",
    "\n",
    "def draw_top(subplot_tuple, img):\n",
    "    plt.subplot(*subplot_tuple)\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Target Face\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "def draw_swap(subplot_tuple, new_pca_array, is_top=False):\n",
    "    global target_batch_rs, G\n",
    "    plt.subplot(*subplot_tuple)\n",
    "\n",
    "    z_embed_diff = pca.calcul_z_embed_diff(new_pca_array, original_pca)\n",
    "    for zattr_id in range(len(z_embed)):\n",
    "        z_embed[zattr_id] = torch.from_numpy((orig_z_embed[zattr_id]+z_embed_diff[zattr_id]).reshape(*original_shape[zattr_id])).half().to(\"cuda\")\n",
    "\n",
    "    Y_st = faceshifter_batch_zattrs(source_embed, z_embed, 1, G)\n",
    "    torch.cuda.empty_cache()\n",
    "    plt.imshow(Y_st[0][:,:,::-1])\n",
    "    \n",
    "    for side in [\"top\", \"right\", \"bottom\", \"left\"]: plt.gca().spines[side].set_visible(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if is_top:\n",
    "        plt.title(\"Swapped (Random)\")\n",
    "\n",
    "\n",
    "set_target(path_to_target=\"examples/images/jaeseung.jpg\")\n",
    "draw_top((num_plotted_pca*3+1, n_ticks, 1), crop_frames_list[0][0][:,:,::-1])\n",
    "draw_swap((num_plotted_pca*3+1, n_ticks, 2), pca_array, is_top=True)\n",
    "\n",
    "set_target(path_to_target=\"examples/images/elon_musk.jpg\")\n",
    "draw_top((num_plotted_pca*3+1, n_ticks, 3), crop_frames_list[0][0][:,:,::-1])\n",
    "draw_swap((num_plotted_pca*3+1, n_ticks, 4), pca_array, is_top=True)\n",
    "\n",
    "set_target(path_to_target=\"examples/images/tgt2.png\")\n",
    "draw_top((num_plotted_pca*3+1, n_ticks, 5), crop_frames_list[0][0][:,:,::-1])\n",
    "draw_swap((num_plotted_pca*3+1, n_ticks, 6), pca_array, is_top=True)\n",
    "\n",
    "for pci_i in range(num_plotted_pca):\n",
    "    interval = (pca_max[pci_i] - pca_min[pci_i]) / (n_ticks-1)\n",
    "    for c in range(n_ticks):\n",
    "        \n",
    "        set_target(path_to_target=\"examples/images/jaeseung.jpg\")\n",
    "        new_pca_array = pca_array.copy()\n",
    "        new_pca_array[0, pci_i] = pca_min[pci_i] + (interval * c)\n",
    "        draw_swap((num_plotted_pca*3+1, n_ticks, (pci_i*3+1)*n_ticks+c+1), new_pca_array)\n",
    "        plt.xlabel(f\"{new_pca_array[0, pci_i]:.2f}\")\n",
    "        if c == 0:\n",
    "            plt.ylabel(\"PCA #{}\".format(pci_i))\n",
    "        set_target(path_to_target=\"examples/images/elon_musk.jpg\")\n",
    "        new_pca_array = pca_array.copy()\n",
    "        new_pca_array[0, pci_i] = pca_min[pci_i] + (interval * c)\n",
    "        draw_swap((num_plotted_pca*3+1, n_ticks, (pci_i*3+2)*n_ticks+c+1), new_pca_array)\n",
    "        plt.xlabel(f\"{new_pca_array[0, pci_i]:.2f}\")\n",
    "        if c == 0:\n",
    "            plt.ylabel(\"PCA #{}\".format(pci_i))\n",
    "        set_target(path_to_target=\"examples/images/tgt2.png\")\n",
    "        new_pca_array = pca_array.copy()\n",
    "        new_pca_array[0, pci_i] = pca_min[pci_i] + (interval * c)\n",
    "        draw_swap((num_plotted_pca*3+1, n_ticks, (pci_i*3+3)*n_ticks+c+1), new_pca_array)\n",
    "        plt.xlabel(f\"{new_pca_array[0, pci_i]:.2f}\")\n",
    "        if c == 0:\n",
    "            plt.ylabel(\"PCA #{}\".format(pci_i))\n",
    "\n",
    "plt.tight_layout()\n",
    "save_path = f\"./pca_figs/doublePCA_for_zattr_src{source_id}_Triple_to{num_plotted_pca}_tmp.png\"\n",
    "plt.savefig(save_path)\n",
    "plt.close()\n",
    "print(f\"saved at {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xaiseung_ghost_cuda114",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
